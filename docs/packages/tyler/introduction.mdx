---
title: 'Tyler Introduction'
description: 'The core agent framework of Slide'
---

## What is Tyler?

Tyler is the heart of the Slide framework - a powerful, async-first agent framework for building autonomous AI applications. It provides everything you need to create, manage, and deploy intelligent agents that can use tools, maintain context, and integrate with external services via MCP.

## Key Features

<CardGroup cols={2}>
  <Card title="Autonomous Agents" icon="robot">
    Create agents that can reason, plan, and execute complex tasks independently
  </Card>
  <Card title="Tool Integration" icon="toolbox">
    Seamlessly integrate with Lye tools or create custom tools
  </Card>
  <Card title="MCP Support" icon="plug">
    Connect to any MCP-compatible server for extended capabilities
  </Card>
  <Card title="Streaming Responses" icon="stream">
    Real-time streaming for better user experience
  </Card>
  <Card title="Context Management" icon="brain">
    Built-in support for conversation history via Narrator
  </Card>
  <Card title="Multiple LLMs" icon="sparkles">
    Support for OpenAI, Anthropic, Google, and more
  </Card>
</CardGroup>

## Installation

<Tabs>
  <Tab title="uv (Recommended)">
    ```bash
    uv add slide-tyler
    ```
  </Tab>
  <Tab title="pip">
    ```bash
    pip install slide-tyler
    ```
  </Tab>
</Tabs>

## Quick Start

### Basic Agent

```python
import asyncio
from tyler import Agent, Thread, Message

# Create a simple agent
agent = Agent(
    name="assistant",
    model_name="gpt-4",
    purpose="To be a helpful assistant"
)

async def main():
    # Create a thread
    thread = Thread()
    
    # Add a message
    message = Message(role="user", content="What is the capital of France?")
    thread.add_message(message)
    
    # Run the agent
    processed_thread, new_messages = await agent.go(thread)
    
    # Print the response
    for msg in new_messages:
        if msg.role == "assistant":
            print(msg.content)
            # Output: "The capital of France is Paris."

if __name__ == "__main__":
    asyncio.run(main())
```

### Agent with Tools

```python
import asyncio
from tyler import Agent, Thread, Message
from lye import WEB_TOOLS, FILES_TOOLS

async def main():
    # Create an agent with tools
    agent = Agent(
        name="researcher",
        model_name="gpt-4",
        purpose="To help with research tasks",
        tools=[*WEB_TOOLS, *FILES_TOOLS]
    )
    # Create thread and message
    thread = Thread()
    message = Message(
        role="user",
        content="Research the latest AI developments and save a summary"
    )
    thread.add_message(message)
    
    # Agent can now search the web and save results
    processed_thread, new_messages = await agent.go(thread)
    
    # View what the agent did
    for msg in new_messages:
        if msg.role == "assistant":
            print(f"Assistant: {msg.content}")
        elif msg.role == "tool":
            print(f"Tool ({msg.name}): {msg.content[:100]}...")

if __name__ == "__main__":
    asyncio.run(main())
```

### Agent with Persistence

```python
import asyncio
from tyler import Agent, Thread, Message, ThreadStore

async def main():
    # Create persistent storage
    thread_store = await ThreadStore.create("sqlite+aiosqlite:///conversations.db")
    
    # Create agent with conversation persistence
    agent = Agent(
        name="chatbot",
        model_name="gpt-4",
        purpose="To be a helpful chatbot with conversation history",
        thread_store=thread_store
    )
    
    # Create or load thread
    thread_id = "chat-001"
    try:
        thread = await thread_store.get_thread(thread_id)
    except:
        thread = Thread(id=thread_id)
    
    # First message
    message1 = Message(role="user", content="My name is Alice")
    thread.add_message(message1)
    processed_thread, _ = await agent.go(thread)
    
    # Save the conversation
    await thread_store.save_thread(processed_thread)
    
    # Agent remembers context
    message2 = Message(role="user", content="What's my name?")
    processed_thread.add_message(message2)
    final_thread, new_messages = await agent.go(processed_thread)
    
    for msg in new_messages:
        if msg.role == "assistant":
            print(msg.content)
            # Output: "Your name is Alice."
    
    # Save the updated conversation
    await thread_store.save_thread(final_thread)

if __name__ == "__main__":
    asyncio.run(main())
```

## Core Concepts

### Agent Lifecycle

```mermaid
stateDiagram-v2
    [*] --> Created: Agent()
    Created --> Initialized: Configure tools/settings
    Initialized --> Ready: Validate configuration
    Ready --> Running: run() or stream()
    Running --> Processing: Execute task
    Processing --> ToolCalling: Use tools
    ToolCalling --> Processing: Tool results
    Processing --> Completed: Generate response
    Completed --> Ready: Await next task
    Ready --> [*]: Cleanup
```

### Tool Selection

Tyler agents intelligently select tools based on the task:

1. **Automatic Selection**: Agent analyzes the task and chooses appropriate tools
2. **Tool Chaining**: Complex tasks may require multiple tools in sequence
3. **Parallel Execution**: Independent tool calls run concurrently for efficiency

### Model Support

Tyler supports multiple LLM providers:

| Provider | Models | Streaming | Tool Calling |
|----------|--------|-----------|--------------|
| OpenAI | GPT-4, GPT-3.5 | ✅ | ✅ |
| Anthropic | Claude 3, Claude 2 | ✅ | ✅ |
| Google | Gemini Pro, Gemini Ultra | ✅ | ✅ |
| Local | Ollama, llama.cpp | ✅ | ⚠️ Limited |

## Architecture

Tyler follows a modular architecture:

```
tyler/
├── models/
│   └── agent.py          # Core Agent class
├── mcp/
│   ├── adapter.py        # MCP integration
│   └── client.py         # MCP client implementation
├── utils/
│   ├── tool_runner.py    # Tool execution engine
│   └── logging.py        # Structured logging
└── cli/
    └── chat.py           # Interactive CLI
```

## Advanced Features

### Custom System Prompts

```python
agent = Agent(
    name="expert",
    model_name="gpt-4",
    purpose="""You are an expert Python developer.
    Always write clean, well-documented code.
    Follow PEP 8 style guidelines."""
)
```

### Tool Configuration

```python
from lye import WEB_TOOLS
from lye.files import read_file

agent = Agent(
    name="controlled-agent",
    model_name="gpt-4",
    purpose="To search and read information",
    tools=[*WEB_TOOLS, read_file],
    tool_choice="auto",           # or "none", "required"
    parallel_tool_calls=True,      # Enable parallel execution
    max_tool_calls=5              # Limit tool usage
)
```

### Error Handling

```python
from tyler.exceptions import AgentError, ToolError

try:
    thread = Thread()
    message = Message(role="user", content="Complex task")
    thread.add_message(message)
    
    processed_thread, new_messages = await agent.go(thread)
except ToolError as e:
    print(f"Tool failed: {e.tool_name} - {e.message}")
except AgentError as e:
    print(f"Agent error: {e}")
```

### Streaming Responses

```python
from tyler import StreamUpdate

# Create thread and message
thread = Thread()
message = Message(role="user", content="Write a story about AI")
thread.add_message(message)

# Stream responses for real-time output
async for update in agent.stream(thread):
    if isinstance(update, StreamUpdate):
        if update.type == "content":
            print(update.content, end="", flush=True)
        elif update.type == "tool_call":
            print(f"\n[Using tool: {update.tool_name}]")
```

## Integration Examples

### With Lye Tools

```python
import asyncio
from tyler import Agent, Thread, Message
from lye import AUDIO_TOOLS, IMAGE_TOOLS, BROWSER_TOOLS

async def main():
    agent = Agent(
        name="multimedia-processor",
        model_name="gpt-4",
        purpose="To process multimedia content",
        tools=[*AUDIO_TOOLS, *IMAGE_TOOLS, *BROWSER_TOOLS]
    )
    thread = Thread()
    message = Message(
        role="user",
        content="Transcribe the audio from this video and analyze any images shown"
    )
    thread.add_message(message)
    
    # Process multimedia content
    processed_thread, new_messages = await agent.go(thread)

if __name__ == "__main__":
    asyncio.run(main())
```

### With MCP Servers

```python
import asyncio
from tyler import Agent, Thread, Message
from tyler.mcp import MCPAdapter

async def main():
    # Connect to MCP server
    adapter = MCPAdapter()
    await adapter.connect("stdio://./custom-tools-server")
    
    # Create agent with MCP tools
    agent = Agent(
        name="mcp-agent",
        model_name="gpt-4",
        purpose="To use MCP tools",
        mcp_adapter=adapter
    )
    
    # Use MCP tools
    thread = Thread()
    message = Message(role="user", content="Use the custom MCP tools to complete this task")
    thread.add_message(message)
    
    processed_thread, new_messages = await agent.go(thread)

if __name__ == "__main__":
    asyncio.run(main())
```

### With Narrator

```python
import asyncio
from tyler import Agent, Thread, Message, ThreadStore, FileStore

async def main():
    # Use PostgreSQL for production
    thread_store = await ThreadStore.create("postgresql://user:pass@localhost/db")
    file_store = await FileStore.create(base_path="./production_files")
    
    agent = Agent(
        name="production-bot",
        model_name="gpt-4",
        purpose="To be a production-ready assistant",
        thread_store=thread_store,
        file_store=file_store
    )
    
    # Agent now has persistent storage for conversations and files
    thread = Thread(id="production-thread-001")
    message = Message(role="user", content="Remember this for next time: my favorite color is blue")
    thread.add_message(message)
    
    processed_thread, _ = await agent.go(thread)
    await thread_store.save_thread(processed_thread)

if __name__ == "__main__":
    asyncio.run(main())
```

## CLI Usage

Tyler includes an interactive CLI for testing:

```bash
# Start interactive chat
tyler chat

# With specific model
tyler chat --model gpt-4

# With tools
tyler chat --tools web.search,files.read

# Connect to MCP server
tyler chat --mcp stdio://./my-server
```

## Testing & Evaluation

Tyler includes a comprehensive evaluation framework for testing your agents:

```python
from tyler import Agent
from tyler.eval import AgentEval, Conversation, Expectation, ToolUsageScorer
from lye import WEB_TOOLS

# Create agent to test
agent = Agent(
    name="test-agent",
    model_name="gpt-4",
    purpose="To help with various tasks",
    tools=WEB_TOOLS
)

# Define test scenarios
eval = AgentEval(
    name="agent_test",
    conversations=[
        Conversation(
            user="What's the weather?",
            expect=Expectation(
                uses_tools=["web-search"],
                tone="helpful"
            )
        )
    ],
    scorers=[ToolUsageScorer()]
)

# Run evaluation (uses mock tools by default)
results = await eval.run(agent)
print(f"Pass rate: {results.pass_rate:.2%}")
```

<Note>
  Evaluations use mock tools by default to prevent real API calls during testing.
</Note>

## Performance Tips

1. **Enable Parallel Tool Calls**: Set `parallel_tool_calls=True` for concurrent execution
2. **Use Appropriate Models**: Match model complexity to task requirements
3. **Cache Responses**: Integrate with Narrator for response caching
4. **Limit Tool Calls**: Set `max_tool_calls` to prevent infinite loops
5. **Stream Long Responses**: Use `stream()` for better perceived performance

## Next Steps

<CardGroup cols={2}>
  <Card
    title="Agent Evaluations"
    icon="flask"
    href="/packages/tyler/evaluations"
  >
    Test and evaluate your agents
  </Card>
  <Card
    title="Agent Configuration"
    icon="cog"
    href="/packages/tyler/agents"
  >
    Deep dive into agent configuration
  </Card>
  <Card
    title="MCP Adapters"
    icon="plug"
    href="/packages/tyler/mcp-adapters"
  >
    Learn about MCP integration
  </Card>
  <Card
    title="Examples"
    icon="code"
    href="/packages/tyler/examples"
  >
    See practical examples
  </Card>
</CardGroup> 